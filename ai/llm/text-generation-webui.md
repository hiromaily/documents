# text-generation-webui

[github](https://github.com/oobabooga/text-generation-webui)

`text-generation-webui`は、主に大規模言語モデル（LLM）用のGradioウェブUIを提供している。このプロジェクトは、複数の推論バックエンドをサポートし、テキスト生成のための使いやすいインターフェースを提供することを目的としている。
このプロジェクトは、テキスト生成のための強力なツールを提供し、ユーザーが簡単に大規模言語モデルを利用できるように設計されている。

## 主な特徴

- **複数のバックエンドサポート**: Transformers、llama.cpp、ExLlamaV2など、さまざまなテキスト生成バックエンドを一つのUI/APIで利用可能。
- **OpenAI互換API**: チャットおよび補完エンドポイントを提供し、簡単に利用できる。
- **自動プロンプトフォーマット**: Jinja2テンプレートを使用してプロンプトを自動的にフォーマット。
- **複数のチャットモード**: 指示、チャット指示、チャットの3つのモードをサポート。
- **過去のチャットメニュー**: 以前の会話に素早く切り替え可能。
- **自由形式のテキスト生成**: デフォルト/ノートブックタブで制限なくテキスト生成が可能。
- **モデルの簡単切り替え**: UI内でモデルを簡単に切り替えられる。
- **LoRA微調整ツール**: シンプルなLoRA微調整ツールを提供。
- **拡張機能のサポート**: 多数の組み込みおよびユーザー提供の拡張機能が利用可能。

- ChatGPT API互換APIサーバとして利用可能
- llama.cppでCPUでもそれなりに動くモデルをlocal LLMとしてホストできる

## インストール手順

1. OSに応じたスクリプトを実行（例: `start_linux.sh`, `start_windows.bat`）。
2. GPUベンダーを選択。
3. インストールが完了したら、`http://localhost:7860`にアクセス。

## 使用方法

- **コマンドラインフラグ**: スクリプトを実行する際に、さまざまなコマンドラインフラグを使用して設定を調整できる。
- **モデルのダウンロード**: Hugging Faceからモデルを自動的にダウンロードする機能もある。

## References

- [local LLMをChatGPT API互換サーバとして使う方法まとめ(2023/10版)](https://qiita.com/takaaki_inada/items/a918ca6984e832bc9741)
