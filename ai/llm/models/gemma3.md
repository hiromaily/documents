# Gemma3

2025年3月12日、Google Developers Blogにて、Gemma 3が発表された。この新しいバージョンは、Gemmaオープンモデルファミリーの中で最も強力で進化したものであり、これまでの成功を基にしている。Gemmaモデルは、これまでに1億回以上ダウンロードされ、コミュニティによって60,000以上のバリエーションが作成されている。

## 新機能

Gemma 3には以下のような新機能が追加されている：

- **マルチモーダリティ**: 画像と言語の入力をサポートし、テキスト出力を行う。
- **コンテキストウィンドウ**: 最大128,000トークンのコンテキストを処理可能。
- **多言語対応**: 140以上の言語を理解。
- **数学、推論、チャット能力の向上**: 構造化された出力や関数呼び出しが可能。
- **サイズのバリエーション**: 1B、4B、12B、27Bの4つのサイズで提供され、事前学習済みモデルと一般的な指示調整バージョンがある。

## Gemmaの構築方法

Gemmaは、以下のプロセスを通じて最適化されている：

- **蒸留**: より大きな指示モデルからGemma 3の事前学習チェックポイントへの蒸留。
- **人間のフィードバックによる強化学習 (RLHF)**: モデルの予測を人間の好みに合わせる。
- **機械のフィードバックによる強化学習 (RLMF)**: 数学的推論を強化。
- **実行フィードバックによる強化学習 (RLEF)**: コーディング能力を向上。

これにより、Gemma 3は数学、コーディング、指示に従う能力が大幅に向上し、LMArenaでのスコアは1338に達した。

## マルチターンテキストと画像入力の例

Gemma 3は、テキストと画像を交互に使用することができ、以下のようなインタラクションが可能：

- **テキストの例**:

   ```
   <bos><start_of_turn>user
   knock knock<end_of_turn>
   <start_of_turn>model
   who is there<end_of_turn>
   ```

- **画像の例**:
  
   ```
   <bos><start_of_turn>user
   Image A: <start_of_image>
   Image B: <start_of_image>
   ```

## ShieldGemma 2

Gemma 3に基づく4Bの画像安全分類器であり、合成画像や自然画像の安全性をモデレートするためのラベルを出力する。

## Gemma 3の活用方法

Gemma 3を試すためのステップは以下の通り：

1. **直接実験**: Google AI Studioを使用してGemma 3を試す。
2. **モデルのダウンロード**: Hugging FaceやKaggleでモデルの重みを見つける。
3. **学習と統合**: 技術報告書や文書を参照してプロジェクトに統合。
4. **開発ツールの利用**: Hugging Face Transformersや新しいGemma JAXライブラリなどを活用。
5. **デプロイ方法の選択**: Google GenAI APIやCloud TPUなど、複数のデプロイオプションを利用可能。

## References

- [Introducing Gemma 3: The Developer Guide](https://developers.googleblog.com/en/introducing-gemma3/)
