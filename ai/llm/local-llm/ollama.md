# Ollama

Ollamaとは、ローカル環境でオープンソースの大規模言語モデル（LLM）を実行できるツール

## 特徴

1. **モデルのダウンロードと実行**: Ollamaは、`LLaMA-2`、`Mistral`、`DeepSeek R1`などのさまざまなモデルのダウンロードと実行をサポートしている。

2. **GPUアクセラレーション**: ハードウェアアクセラレーションに対応しており、NVIDIA GPUやIntel AVX/AVX2などのCPU命令セットを使用してモデルの実行を高速化する。

3. **効率的なモデル管理**: モデルの重み、設定、データセットを一つのモデルファイルで管理し、自動的なメモリ割り当てを行う.

4. **幅広いモデルへの対応**: 様々なLLMに対応しており、ユーザーはスムーズにモデルを切り替えることができる.

5. **Web UIオプション**: Ollamaは、ユーザーフレンドリーなWeb UIオプションを提供し、簡単にモデルを使用できる.

6. **CLIリファレンスとAPI**: モデルの作成、更新、削除など、さまざまなCLIコマンドを提供し、REST APIも利用可能.

7. **ツールコール機能**: Ollamaは、LLMが外部ツールやAPIと連携するためのメカニズムを提供する。これにより、リアルタイムでのデータ取得や特定のタスクの実行が可能となる.

Ollamaは、開発者や研究者がローカルでLLMを効率的に扱うことができるツールであり、AIの進化に大きな役割を果たしている。

## 使い方

[公式](https://ollama.com/download)からtoolをダウンロード

```sh
ollama run llama3.2
```

## その他の類似ツール

- [LM Studio](https://lmstudio.ai/)
  - [Gemma3](https://blog.google/technology/developers/gemma-3/)のダウンロードが可能
