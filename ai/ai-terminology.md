# AI 専門用語


## AGI（artificial general intelligence）

今日よく知られているAIよりもさらに高度なバージョンのAIを示す概念。人間よりもはるかに優れた能力でタスクをこなしつつ、自ら学習・進化していく能力を持つものを指す。日本語では一般に「汎用人工知能」と訳されることが多い。

## エージェンティブ（agentive）

　目標達成のために自律的に行動を起こす能力（エージェンシー）を持つシステムやモデルを指す。AI分野においては、自動運転車のように常時監視なしで行動を決定できるモデルなどが例として挙げられる。
なお、英語では「agentic」という形容詞もあり、「行為主体性を備えた」というニュアンスをもつことが多いが、「agentive」との使い分けは必ずしも統一されていない。「agentive technology」という場合は、ユーザーの目標達成を自律的に支援する技術を指すなど、文脈により若干の意味合いの差がある。

## AIエージェント（AI agent）
（注：国内編集部が追加）
AIエージェントとは、コンピューターが自律的に判断し行動できる仕組みのことだ。たとえば、人間が「この仕事をやっておいて」と指示したとき、AIエージェントは与えられたルールや情報をもとに、どのように作業を進めるかや、何をすべきかを自分で判断する。わからないことがあれば追加の情報を取りに行き、答えが見つかったらまた作業を続けることもできる。ただチャットアプリで質問に答えるだけではなく、必要な情報を自動で取得したり、スケジュール管理を代行したりするなど、人間の手間を省くために自律的に動ける点がAIエージェントの特徴だ。

## AI倫理（AI ethics）

AIが人間に害を及ぼさないようにするための原則を指す。具体的には、AIシステムがどのようにデータを収集するか、またはバイアスに対処するかなどを定めることで実現される。

## AI安全性（AI safety）

AI技術がもたらしうる安全上のリスクを学際的に研究する分野。短期的には自動運転や医療AIなどの誤作動・事故などに対応し、長期的には突然の進化による超知能が人間にとって脅威となる可能性も懸念・検討する。いずれも意図せぬ形でAIが暴走したり、人間に有害な行動をとるリスクを回避するのが目的となる。

## アルゴリズム（algorithm）

問題を解決したり何らかの計算処理を行ったりするための、一連の手続き・手順のこと。AIや機械学習における「学習アルゴリズム」もその一種だが、ソートや暗号化など多岐にわたる分野で利用される。

## アライメント（alignment）

AIが望ましい結果を出すように調整すること。コンテンツのモデレーションや、人間に対してポジティブな反応を保つようにするなど、幅広い場面で用いられる。

## 擬人化（anthropomorphism）

人間が人間でないものに対して、人間的な性質を与えてしまうこと。AIでは、チャットボットが実際以上に人間的あるいは意識を持っていると考えてしまうこと（たとえば「喜んでいる」「悲しんでいる」「感情や自我がある」と信じるなど）が該当する。

## 人工知能（artificial intelligence）

コンピュータプログラムやロボットを用いて人間の知能を模倣する技術を指す。人間が行うタスクをコンピュータシステムにこなさせることを目的とした、コンピュータサイエンスの分野。日本語では「人工知能」と呼ばれる。

## 自律エージェント（autonomous agents）

特定のタスクを達成するために必要な能力やプログラム、その他のツールを備えたAIモデルを指す。たとえば自動運転車は、センサー入力、GPS、運転アルゴリズムを用いて自律的に道路を走行できるため、自律エージェントに該当する。スタンフォード大学の研究では、自律エージェントが独自の文化や伝統、共有言語を発達させる可能性が示されている。

## バイアス（bias）

大規模言語モデルにおいては、学習データに起因する誤りのことを指す。これにより、特定の人種や集団にステレオタイプ的な特徴を誤って結び付けるなどの問題が生じる場合がある。

## チャットボット（chatbot）

人間の言語を模倣してテキストを通じてやり取りするプログラム。ユーザーとの会話を疑似的に再現し、質問に答えたり、情報を提供したりする。

## ChatGPT

OpenAIによって開発されたAIチャットボット。大規模言語モデル技術を用いて、人間のような文章を生成する。

## 認知コンピューティング（cognitive computing）

人工知能を指すもうひとつの呼称。人間の認知能力を模倣するコンピュータの技術やシステムを指す場合に用いられることが多い。

## データ拡張（data augmentation）

AIを学習させる際に、既存のデータを加工・リミックスしたり、より多様なデータを追加したりすることで、学習モデルの性能を向上させる手法。

## 深層学習（deep learning）

AIの一手法であり、機械学習のサブフィールドでもある。多数のパラメータを用いて画像、音声、テキストなどの複雑なパターンを認識する。人間の脳をモデルにした人工ニューラルネットワークを用いて、特徴を自動的に学習する。

## 拡散（diffusion）

機械学習の手法の一つで、たとえば画像などの既存データにランダムノイズを加え、それをネットワークが再構築（ノイズを除去）するように学習させる。拡散モデルはこのプロセスを通じて新たな生成能力を獲得する。

## 創発的振る舞い（emergent behavior）

AIモデルが、開発者が意図していなかった新たな能力や動作を示す現象のこと。

## エンドツーエンド学習（end-to-end learning）

深層学習のプロセスで、タスクを最初から最後まで通しで学習させる手法。タスクを部分ごとに順番に学習させるのではなく、入力データから直接、全体を一括で学習する。

## 倫理的配慮（ethical considerations）

AIに関わるプライバシー、データ利用、公平性、悪用リスクなど、安全面を含めた倫理的な問題を考慮すること。

## フーム（foom）

fast takeoffやhard takeoffとも呼ばれる概念。もし汎用人工知能（AGI）が完成した場合、それが非常に急速に進化し、人類にとって手遅れになるほどの脅威となる可能性を示唆する。

## 敵対的生成ネットワーク（generative adversarial networks）

生成器（Generator）と識別器（Discriminator）の2つのニューラルネットワークで構成される生成系AIモデル。生成器が新たなデータを作り、識別器がそれを判定することで、双方が競合的に学習を進める仕組み。

## 生成AI（generative AI）

テキスト、映像、プログラムコード、画像など、さまざまなコンテンツをAIが生成する技術。大量のデータを学習し、パターンを見つけ出して新たなコンテンツを生み出す。元のデータに似た出力が作られることもある。

## Google Gemini

Googleが開発中の大規模言語モデル（LLM）とそのチャットサービス。ChatGPTとの比較で語られることも多い。

## ペーパークリップ問題（paperclips）

オックスフォード大学の哲学者ニック・ボストロムが提唱した「Paperclip Maximiser」という仮説的なシナリオ。AIシステムが「できるだけ多くのペーパークリップを作る」という目標を追求した結果、あらゆる資源をペーパークリップ製造に振り向けてしまう。最悪の場合、人類にとって有益な機械や資源まで分解して素材にし、結果的に人類を破滅へ追い込む恐れがあるという想定。

## パラメータ（parameters）

大規模言語モデル（LLM）の構造や動作を左右する数値のこと。モデルが予測を行う際の基盤となる。

## Perplexity

Perplexity AI社が提供するAIチャットボット兼検索エンジンの名称。他のAIチャットボットと同様に大規模言語モデルを活用し、新規の回答を生成する。オープンなインターネットへ接続しているため、最新情報を含む検索結果を取得できる。有料版のPerplexity Proでは、GPT-4oやClaude 3 Opus、Mistral Large、オープンソースのLlaMa 3、自社のSonar 32kなどのモデルが利用可能。Proユーザーはドキュメントをアップロードしての解析、画像生成、コード解釈などの追加機能も使える。

## プロンプト（prompt）

AIチャットボットに対して入力する指示や質問のこと。回答を得るためのきっかけとなる。

## プロンプト・チェイニング（prompt chaining）

AIへの指示（プロンプト）やその出力を複数回にわたって連続的につなぎ、段階的に高度なタスクを実行させる手法。単に会話履歴を記憶するだけでなく、前段階の出力を次の段階のプロンプトに組み込むなど、複数ステップにわたるプロセスを意図的に設計することで、より精緻または複雑な処理を行いやすくする。

## 確率的オウム（stochastic parrot）

大規模言語モデル（LLM）を例える比喩。出力がどれだけ自然でも、実際には言語や世界の意味を理解しているわけではない、ということを指す。オウムが人間の言葉を真似しても、その意味を理解しているわけではない、という状況になぞらえている。

## スタイル転移（style transfer）

AIがある画像の内容を別の画像のスタイルで再表現する技術。たとえば、レンブラントの自画像をピカソの画風で描き直すような応用ができる。

## テンパラチャー（temperature）

言語モデルの出力の「ランダムさ」を制御するパラメータ。値を高くすると、より大胆で創造的な回答が得られるが、不正確な回答も増える可能性がある。

## テキスト・トゥ・イメージ生成（text-to-image generation）

テキストによる指示をもとにAIが画像を生成する技術。

## トークン（tokens）

AI言語モデルが処理する際にテキストを分割した最小単位。英語の場合、約4文字、もしくは1単語の一部分に相当する。

## 訓練データ（training data）

AIモデルが学習するときに使うテキスト、画像、コードなどのデータ全般。

## トランスフォーマーモデル（transformer model）

ニューラルネットワークの一種で、文や画像内の要素同士の関係を同時に把握しながら学習する構造。単語を一つずつ順番に処理するのではなく、一文全体や画像全体を見てコンテクストを理解する仕組み。

## チューリングテスト（turing test）

数学者・計算機科学者アラン・チューリング氏にちなんで名付けられたテスト。機械がどれほど人間らしく振る舞うかを試す基準で、人間の質問者が機械と人間の応答を区別できなければ合格とされる。

## 教師なし学習（unsupervised learning）

ラベル付けされた訓練データを用意せずに、モデルがデータ内のパターンを自ら見つけ出す機械学習の手法。

## 弱いAI / 狭いAI（weak AI / narrow AI）

特定のタスクにのみ特化したAI。自分のスキル範囲外を学習することはできず、現在の多くのAIシステムはこのカテゴリーに属する。

## ゼロショット学習（zero-shot learning）

必要な訓練データが与えられていない状況で、モデルがタスクをこなすこと。たとえばトラの画像でしか学習していないモデルが、ライオンを見分けられるようになるケースなどが挙げられる。
